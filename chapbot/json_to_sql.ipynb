{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def json_to_sql(filename):\n",
    "#     print(\"starting read of \",filename)\n",
    "    with filename.open(buffering=10000) as f:\n",
    "        for line in f:\n",
    "            text=line\n",
    "            parse=json.loads(text)\n",
    "            row = parse\n",
    "            author = row['author']\n",
    "            body = format_text(row['body'])\n",
    "            controversiality= row['controversiality']\n",
    "            created_utc= row['created_utc']\n",
    "            edited= row['edited']\n",
    "            gilded= row['gilded']\n",
    "            id_ = row['id']\n",
    "            link_id = row['link_id']\n",
    "            parent_id = row['parent_id']\n",
    "            score= row['score']\n",
    "            stickied = row['stickied']\n",
    "            subreddit = row['subreddit']\n",
    "            ups= row['ups']\n",
    "            params=[link_id, author, body, parent_id, subreddit, ups, score, stickied, controversiality, created_utc, edited, gilded, id_]\n",
    "#             print(params)\n",
    "            try:\n",
    "                transaction_bldr(params)\n",
    "            except Exception as e:\n",
    "                print('error: ',str(e))\n",
    "\n",
    "                \n",
    "def transaction_bldr(sql):\n",
    "    global sql_transaction_list\n",
    "    sql_transaction_list.append(sql)\n",
    "    if len(sql_transaction_list) > 1000:\n",
    "        try:\n",
    "            c.executemany(\"\"\"INSERT INTO reddit_comment_table (link_id, author, body, parent_id, subreddit, ups, score, stickied, controversiality, created_utc, edited, gilded, id_) \\\n",
    "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\", sql_transaction_list)\n",
    "        except Exception as e:\n",
    "            print('error', str(e))\n",
    "        cxn.commit()   \n",
    "        sql_transaction_list=[]\n",
    "# def transaction_bldr(sql):\n",
    "#     global sql_transaction\n",
    "#     sql_transaction.append(sql)\n",
    "#     if len(sql_transaction) > 1000:\n",
    "#         c.execute('BEGIN TRANSACTION')\n",
    "#         for s in sql_transaction:\n",
    "#             try:\n",
    "#                 c.execute(s)\n",
    "#             except:\n",
    "#                 pass\n",
    "#         connection.commit()\n",
    "#         sql_transaction = []\n",
    "        \n",
    "\n",
    "\n",
    "def create_table():\n",
    "    c.execute(\"\"\"CREATE TABLE IF NOT EXISTS reddit_comment_table (link_id TEXT PRIMARY_KEY,\n",
    "id_ TEXT,\n",
    "parent_id TEXT,\n",
    "author TEXT,\n",
    "body TEXT,\n",
    "subreddit TEXT,\n",
    "controversiality INT, \n",
    "created_utc INT,\n",
    "edited TEXT,\n",
    "gilded INT,\n",
    "score INT,\n",
    "stickied \n",
    "subreddit TEXT,\n",
    "ups INT) \"\"\")\n",
    "    cxn.commit()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "cwd = Path(os.getcwd())\n",
    "filedir=cwd.parents[0] / \"reddit\" / \"2005\" / \"RC_2005-12\"\n",
    "\n",
    "file=Path(filedir)\n",
    "\n",
    "parsed=[]\n",
    "parse=\"\"\n",
    "\n",
    "timeframe='2005-12'\n",
    "sql_transaction=[]\n",
    "cxn=sqlite3.connect('{}.db'.format(timeframe))\n",
    "c = cxn.cursor()\n",
    "    \n",
    "create_table() \n",
    "\n",
    "json_to_sql(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for reference with regards to directory walking\n",
    "# quake_df = pd.DataFrame(columns=['quakename', 'sensor_id', 'max_sensor'])\n",
    "# #print(quake_df)\n",
    "\n",
    "# for paths, dir, files in os.walk('/home/skyler/Downloads/data/csn'):\n",
    "#     #print(dirnames)\n",
    "#     for f in files:\n",
    "#         #print(f)\n",
    "#         filename = os.path.join(paths,f)\n",
    "#         #print(os.path.basename(os.path.dirname(filename)))\n",
    "#         #print(os.path.dirname(filename))\n",
    "#         path = os.path.dirname(filename)\n",
    "#         os.chdir(path)\n",
    "# #       read here\n",
    "\n",
    "    \n",
    "    \n",
    "# #       st = read(f, debug_headers=True)\n",
    "# #       print(max(st[0].data))\n",
    "# #       quake_df=quake_df.append({'quakename': os.path.basename(os.path.dirname(filename)), 'sensor_id': f, 'max_sensor': max(st[0].data)-np.median(st[0].data), 'max_clock': np.argmax(st[0].data),'min_sensor': min(st[0].data,)-np.median(st[0].data), 'min_clock': np.argmin(st[0].data),'Latitude':st[0].stats.sac['stla'],'Longitude':st[0].stats.sac['stlo']}, ignore_index=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab_sql in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (0.3.1)\n",
      "Requirement already satisfied: jsonschema>=3 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jupyterlab_sql) (3.0.1)\n",
      "Requirement already satisfied: sqlalchemy in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jupyterlab_sql) (1.3.6)\n",
      "Requirement already satisfied: jupyterlab in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jupyterlab_sql) (1.1.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jsonschema>=3->jupyterlab_sql) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jsonschema>=3->jupyterlab_sql) (0.15.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jsonschema>=3->jupyterlab_sql) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jsonschema>=3->jupyterlab_sql) (41.2.0)\n",
      "Requirement already satisfied: notebook>=4.3.1 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jupyterlab->jupyterlab_sql) (5.7.8)\n",
      "Requirement already satisfied: jinja2>=2.10 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jupyterlab->jupyterlab_sql) (2.10.1)\n",
      "Requirement already satisfied: tornado!=6.0.0,!=6.0.1,!=6.0.2 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jupyterlab->jupyterlab_sql) (5.1.1)\n",
      "Requirement already satisfied: jupyterlab-server~=1.0.0 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jupyterlab->jupyterlab_sql) (1.0.6)\n",
      "Requirement already satisfied: ipykernel in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (4.10.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.8.2)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (5.3.1)\n",
      "Requirement already satisfied: prometheus-client in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (4.5.0)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (4.3.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (18.0.2)\n",
      "Requirement already satisfied: nbconvert in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (5.5.0)\n",
      "Requirement already satisfied: nbformat in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (4.4.0)\n",
      "Requirement already satisfied: Send2Trash in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (1.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jinja2>=2.10->jupyterlab->jupyterlab_sql) (1.1.1)\n",
      "Requirement already satisfied: json5 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jupyterlab-server~=1.0.0->jupyterlab->jupyterlab_sql) (0.8.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from ipykernel->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (5.8.0)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from terminado>=0.8.1->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from jupyter-client>=5.2.0->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (2.8.0)\n",
      "Requirement already satisfied: decorator in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (4.4.0)\n",
      "Requirement already satisfied: pygments in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (2.4.2)\n",
      "Requirement already satisfied: bleach in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (3.1.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (1.4.2)\n",
      "Requirement already satisfied: testpath in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.6.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from nbconvert->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.3)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.8.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (1.0.16)\n",
      "Requirement already satisfied: pickleshare in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (4.7.0)\n",
      "Requirement already satisfied: webencodings in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.5.1)\n",
      "Requirement already satisfied: wcwidth in /home/skyler/Documents/NN/tf/lib/python3.5/site-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->jupyterlab_sql) (0.1.7)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "{\n",
      "    \"author\": \"sempf\",\n",
      "    \"author_flair_css_class\": null,\n",
      "    \"author_flair_text\": null,\n",
      "    \"body\": \"Again.  Relax.  It's funny.  Sheesh.\",\n",
      "    \"controversiality\": 0,\n",
      "    \"created_utc\": 1136073220,\n",
      "    \"distinguished\": null,\n",
      "    \"edited\": false,\n",
      "    \"gilded\": 0,\n",
      "    \"id\": \"c2713\",\n",
      "    \"link_id\": \"t3_22542\",\n",
      "    \"parent_id\": \"t1_c2701\",\n",
      "    \"retrieved_on\": 1473821517,\n",
      "    \"score\": 9,\n",
      "    \"stickied\": false,\n",
      "    \"subreddit\": \"reddit.com\",\n",
      "    \"subreddit_id\": \"t5_6\",\n",
      "    \"ups\": 9\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# !pip install jupyterlab_sql\n",
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cwd = Path(os.getcwd())\n",
    "filedir=cwd.parents[0] / \"reddit\" / \"2005\" / \"RC_2005-12\"\n",
    "\n",
    "file=Path(filedir)\n",
    "\n",
    "parsed=[]\n",
    "parse=\"\"\n",
    "\n",
    "with file.open() as f:\n",
    "    for line in f:\n",
    "        text=line\n",
    "        parsed.append(json.loads(text))\n",
    "        parse=json.loads(text)\n",
    "#         print(json.dumps(parse, indent=4, sort_keys=True))\n",
    "# print(parsed)\n",
    "print(json.dumps(parse, indent=4, sort_keys=True))\n",
    "\n",
    "timeframe='2005-12'\n",
    "sql_transaction=[]\n",
    "cxn=sqlite3.connect('{}.db'.format(timeframe))\n",
    "c = cxn.cursor()\n",
    "\n",
    "\n",
    "# creates table if it does not exist\n",
    "def create_table():\n",
    "    c.execute(\"\"\"CREATE TABLE IF NOT EXISTS reddit_comment_table (link_id TEXT PRIMARY_KEY,\n",
    "id_ TEXT,\n",
    "parent_id TEXT,\n",
    "author TEXT,\n",
    "body TEXT,\n",
    "subreddit TEXT,\n",
    "controversiality INT, \n",
    "created_utc INT,\n",
    "edited TEXT,\n",
    "gilded INT,\n",
    "score INT,\n",
    "stickied \n",
    "subreddit TEXT,\n",
    "ups INT) \"\"\")\n",
    "    cxn.commit()\n",
    "\n",
    "create_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t3_22542', 'sempf', \"Again.  Relax.  It's funny.  Sheesh.\", 't1_c2701', 'reddit.com', 9, 0, 1136073220, False, 0, 'c2713', 9, False]\n"
     ]
    }
   ],
   "source": [
    "# sample operations to clean up and prep data for SQL submission \n",
    "\n",
    "# where we clean up the body text\n",
    "# TODO: expand it from STUB function\n",
    "def format_text(data):\n",
    "    return data\n",
    "\n",
    "\n",
    "row = parse\n",
    "author = row['author']\n",
    "body = format_text(row['body'])\n",
    "controversiality= row['controversiality']\n",
    "created_utc= row['created_utc']\n",
    "edited= row['edited']\n",
    "gilded= row['gilded']\n",
    "id_ = row['id']\n",
    "link_id = row['link_id']\n",
    "parent_id = row['parent_id']\n",
    "score= row['score']\n",
    "stickied = row['stickied']\n",
    "subreddit = row['subreddit']\n",
    "ups= row['ups']\n",
    "params=[link_id, author, body, parent_id, subreddit, ups, controversiality, created_utc, edited, gilded, id_, score, stickied]\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
