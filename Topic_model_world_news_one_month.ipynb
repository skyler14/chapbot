{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hannah\\Anaconda3\\lib\\site-packages\\past\\builtins\\misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "# Using one month's worth of world news posts\n",
    "'''12-1-2019 EDA'''\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer # CountVectorizer converts a collection of text documents to a matrix of token counts\n",
    "import warnings\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA # Load LDA model from SKL\n",
    "from collections import Counter\n",
    "import pyLDAvis # For interactive topic model visualization\n",
    "from pyLDAvis import sklearn as sklearn_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Hannah\\\\Desktop\\\\UT_Austin\\\\Analytics_MSBA\\\\Fall_19\\\\Data_mgmt_intro\\\\Final_project\\\\worldnews_0619.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>gilded</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boarders huh</td>\n",
       "      <td>J_Man2743</td>\n",
       "      <td>1559518235</td>\n",
       "      <td>t5_2qh13</td>\n",
       "      <td>t3_a78kyo</td>\n",
       "      <td>t3_a78kyo</td>\n",
       "      <td>0</td>\n",
       "      <td>1568784725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>epuwwc7</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[removed]</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1561011745</td>\n",
       "      <td>t5_2qh13</td>\n",
       "      <td>t3_aeu81p</td>\n",
       "      <td>t1_erl6n3x</td>\n",
       "      <td>0</td>\n",
       "      <td>1570329691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>erm9r84</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think you know less when you think that Stal...</td>\n",
       "      <td>steeritupld</td>\n",
       "      <td>1560168854</td>\n",
       "      <td>t5_2qh13</td>\n",
       "      <td>t3_andfac</td>\n",
       "      <td>t1_eqmsv60</td>\n",
       "      <td>0</td>\n",
       "      <td>1569348202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eqmx6le</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       author  \\\n",
       "0                                       Boarders huh    J_Man2743   \n",
       "1                                          [removed]    [deleted]   \n",
       "2  I think you know less when you think that Stal...  steeritupld   \n",
       "\n",
       "   created_utc subreddit_id    link_id   parent_id  score  retrieved_on  \\\n",
       "0   1559518235     t5_2qh13  t3_a78kyo   t3_a78kyo      0    1568784725   \n",
       "1   1561011745     t5_2qh13  t3_aeu81p  t1_erl6n3x      0    1570329691   \n",
       "2   1560168854     t5_2qh13  t3_andfac  t1_eqmsv60      0    1569348202   \n",
       "\n",
       "   controversiality  gilded       id  subreddit  \n",
       "0                 0       0  epuwwc7  worldnews  \n",
       "1                 0       0  erm9r84  worldnews  \n",
       "2                 0       0  eqmx6le  worldnews  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "# Remove null comments\n",
    "df = df[pd.notnull(df['body'])]\n",
    "\n",
    "# Convert all posts to string\n",
    "df['body'] = df['body'].astype(str)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:7: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:7: DeprecationWarning: invalid escape sequence \\w\n",
      "<ipython-input-7-26edbc285c0a>:7: DeprecationWarning: invalid escape sequence \\w\n",
      "  df['body_sw_p'] = df['body_sw'].str.replace('[^\\w\\s]', '').str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Clean data\n",
    "\n",
    "# Remove stopwords\n",
    "df['body_sw'] = df['body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# Remove special characters, make all characters lowercase\n",
    "df['body_sw_p'] = df['body_sw'].str.replace('[^\\w\\s]', '').str.lower()\n",
    "\n",
    "# Remove other common words\n",
    "mask = df['body_sw_p'].str.contains('deleted','people')\n",
    "df=df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the count vectorizer with the English stop words\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the processed titles to get matrix of token counts\n",
    "count_data_tokens = count_vectorizer.fit_transform(df['body_sw_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# Function to print topics and the top 10 labels in each\n",
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names() #words in corpus\n",
    "    for topic_idx, topic in enumerate(model.components_): #enumerate adds a counter to an iterable\n",
    "        print(\"\\nTopic #%d:\" % topic_idx) #%d is used as a placeholder for numeric or decimal values\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])) #numpy.argsort() returns the indices that would sort an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "israel law state government international saudi deal gt land peace\n",
      "\n",
      "Topic #1:\n",
      "im like sure time ive pretty know thanks people really\n",
      "\n",
      "Topic #2:\n",
      "people like children want think dont know care life kids\n",
      "\n",
      "Topic #3:\n",
      "people women men like religious religion different culture society think\n",
      "\n",
      "Topic #4:\n",
      "war iran military iraq like country wars weapons think world\n",
      "\n",
      "Topic #5:\n",
      "countries uk people country eu world europe economy rich money\n",
      "\n",
      "Topic #6:\n",
      "change free speech rights human right freedom climate people like\n",
      "\n",
      "Topic #7:\n",
      "gt said far welcome version best comments reduced make tldr\n",
      "\n",
      "Topic #8:\n",
      "reddit account automatically questions contact action moderators read concerns rworldnews\n",
      "\n",
      "Topic #9:\n",
      "china chinese people hong government kong flag like protest hk\n",
      "\n",
      "Topic #10:\n",
      "people like im said think thats point know saying say\n",
      "\n",
      "Topic #11:\n",
      "money pay companies people company business tax like make government\n",
      "\n",
      "Topic #12:\n",
      "like money good food meat eat make people animals sounds\n",
      "\n",
      "Topic #13:\n",
      "removed energy carbon emissions co2 coal gas solar fossil power\n",
      "\n",
      "Topic #14:\n",
      "trump people right president like vote party left think hes\n",
      "\n",
      "Topic #15:\n",
      "iran oil nuclear iranian ship ships attack power drone russia\n",
      "\n",
      "Topic #16:\n",
      "fuck lol hes news man lmao thats media sorry got\n",
      "\n",
      "Topic #17:\n",
      "like fucking shit water thats plastic day god air hot\n",
      "\n",
      "Topic #18:\n",
      "change climate going years people planet earth world time think\n",
      "\n",
      "Topic #19:\n",
      "years ampx200b ago states yes number canada 20 japan united\n"
     ]
    }
   ],
   "source": [
    "# Tweak the two parameters below\n",
    "number_topics = 20\n",
    "number_words = 10\n",
    "\n",
    "# Create and fit the LDA model\n",
    "# n_jobs specifyies the maximum number of concurrently running jobs. If set to -1, all CPUs are used. \n",
    "# n_components number of features which a transformer should transform the input into\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1, random_state=47)\n",
    "lda.fit(count_data_tokens)\n",
    "\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hannah\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "# # Support visual to see the separation between topic components and the label frequencies for each.\n",
    "# LDAvis_prepped = sklearn_lda.prepare(lda, count_data_tokens, count_vectorizer)\n",
    "# pyLDAvis.display(LDAvis_prepped)\n",
    "# pyLDAvis.save_html(LDAvis_prepped, './LDAvis_prepped'+ str(number_topics) +'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Topic</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004636</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.097844</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.136418</td>\n",
       "      <td>0.071686</td>\n",
       "      <td>0.090559</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>0.041389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030959</td>\n",
       "      <td>0.047018</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.39899</td>\n",
       "      <td>0.03874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101httpwwwredditcomrhelpcomments2bx3cjreddit_101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12nm</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.975803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.970884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Topic                                                   1         2   \\\n",
       "Term                                                                   \n",
       "10                                                0.004636  0.009437   \n",
       "101httpwwwredditcomrhelpcomments2bx3cjreddit_101       NaN       NaN   \n",
       "12nm                                                   NaN       NaN   \n",
       "1948                                                   NaN       NaN   \n",
       "1967                                                   NaN       NaN   \n",
       "\n",
       "Topic                                                   3         4   \\\n",
       "Term                                                                   \n",
       "10                                                0.005794  0.097844   \n",
       "101httpwwwredditcomrhelpcomments2bx3cjreddit_101       NaN       NaN   \n",
       "12nm                                                   NaN       NaN   \n",
       "1948                                                   NaN       NaN   \n",
       "1967                                                   NaN       NaN   \n",
       "\n",
       "Topic                                                   5         6   \\\n",
       "Term                                                                   \n",
       "10                                                0.007781  0.136418   \n",
       "101httpwwwredditcomrhelpcomments2bx3cjreddit_101       NaN       NaN   \n",
       "12nm                                                   NaN       NaN   \n",
       "1948                                                   NaN       NaN   \n",
       "1967                                                   NaN       NaN   \n",
       "\n",
       "Topic                                                   7         8   \\\n",
       "Term                                                                   \n",
       "10                                                0.071686  0.090559   \n",
       "101httpwwwredditcomrhelpcomments2bx3cjreddit_101       NaN       NaN   \n",
       "12nm                                                   NaN  0.975803   \n",
       "1948                                                   NaN       NaN   \n",
       "1967                                                   NaN       NaN   \n",
       "\n",
       "Topic                                                   9         10  \\\n",
       "Term                                                                   \n",
       "10                                                0.005298  0.006953   \n",
       "101httpwwwredditcomrhelpcomments2bx3cjreddit_101       NaN       NaN   \n",
       "12nm                                                   NaN       NaN   \n",
       "1948                                                   NaN  0.994645   \n",
       "1967                                                   NaN  0.970884   \n",
       "\n",
       "Topic                                                   11  12        13  \\\n",
       "Term                                                                       \n",
       "10                                                0.041389 NaN  0.030959   \n",
       "101httpwwwredditcomrhelpcomments2bx3cjreddit_101       NaN NaN       NaN   \n",
       "12nm                                                   NaN NaN       NaN   \n",
       "1948                                                   NaN NaN       NaN   \n",
       "1967                                                   NaN NaN       NaN   \n",
       "\n",
       "Topic                                                   14        15  \\\n",
       "Term                                                                   \n",
       "10                                                0.047018  0.002649   \n",
       "101httpwwwredditcomrhelpcomments2bx3cjreddit_101       NaN       NaN   \n",
       "12nm                                                   NaN       NaN   \n",
       "1948                                                   NaN       NaN   \n",
       "1967                                              0.027063       NaN   \n",
       "\n",
       "Topic                                                   16  17        18  \\\n",
       "Term                                                                       \n",
       "10                                                0.003973 NaN       NaN   \n",
       "101httpwwwredditcomrhelpcomments2bx3cjreddit_101       NaN NaN  0.999662   \n",
       "12nm                                                   NaN NaN       NaN   \n",
       "1948                                                   NaN NaN       NaN   \n",
       "1967                                                   NaN NaN       NaN   \n",
       "\n",
       "Topic                                                  19       20  \n",
       "Term                                                                \n",
       "10                                                0.39899  0.03874  \n",
       "101httpwwwredditcomrhelpcomments2bx3cjreddit_101      NaN      NaN  \n",
       "12nm                                                  NaN      NaN  \n",
       "1948                                                  NaN      NaN  \n",
       "1967                                                  NaN      NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # (i) A file showing which words load on which topics\n",
    "\n",
    "# temp = pd.DataFrame(LDAvis_prepped[2])\n",
    "# temp = temp.reset_index()\n",
    "# temp = temp\n",
    "# #.rename(columns={4: 'Wildlife', 2: 'Water', 3: 'Photography', 1: 'Landscape', 5: 'Culture'})\n",
    "# pd.crosstab(temp['Term'],temp['Topic'],values=temp['Freq'],aggfunc=sum).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
